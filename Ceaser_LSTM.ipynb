{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b209615-a0a5-46e8-9c7a-57339acb4a92",
   "metadata": {},
   "source": [
    "Task: Train a neural network to decrypt text encoded with the Caesar cipher.\n",
    "\n",
    "The essence of the Caesar cipher is as follows: each letter of the alphabet is replaced by another letter that is shifted a fixed number of positions forward or backward in the alphabet.\n",
    "\n",
    "In this case, the encryption process involves the following steps:\n",
    "\n",
    "A key (shift) is chosen, which determines how many positions each letter will be shifted.\n",
    "\n",
    "Each letter of the original text is replaced with the one that is located the chosen number of positions ahead in the alphabet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774aeb13-e5c1-4eee-bd45-4ce9256150b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eca2331-a6ed-4e28-8b7b-a6d22fc15c23",
   "metadata": {},
   "source": [
    "For training the neural network, we will use the text used in the practical session. We will load it, remove punctuation marks (except for internal spaces), and slice it into chunks of 60 characters to obtain approximately 10,000 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2383df0-5870-460e-9501-d621fb2649c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-09 17:36:15--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.179.61, 52.217.19.38, 52.217.122.96, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.179.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 600901 (587K) [text/plain]\n",
      "Saving to: ‘nietzsche.txt.1’\n",
      "\n",
      "nietzsche.txt.1     100%[===================>] 586.82K   397KB/s    in 1.5s    \n",
      "\n",
      "2025-05-09 17:36:18 (397 KB/s) - ‘nietzsche.txt.1’ saved [600901/600901]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/text-datasets/nietzsche.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcd00e9e-1f86-4a75-a5f3-1e9ca87b8645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 600893\n",
      "Processed length: 579262\n",
      "Processed examples: 9654\n",
      "Example length: 60\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import random\n",
    "import tqdm\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "with open('nietzsche.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print('Original length:', len(text))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-z ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "    \n",
    "text = preprocess_text(text)\n",
    "print('Processed length:', len(text))\n",
    "\n",
    "# We will take slices of 60 characters, so we will trim the text to ensure it divides evenly into chunks of 60 characters. Otherwise, we will have slices of different lengths.\n",
    "text = text[:(len(text) // 60) * 60]\n",
    "\n",
    "example_length = 60\n",
    "#Create slices\n",
    "examples = [text[i:i + example_length] for i in range(0, len(text), example_length)]\n",
    "\n",
    "# Remove empty lines (which consist only of spaces)\n",
    "examples = [example for example in examples if len(example) == 60]\n",
    "\n",
    "print(f\"Processed examples: {len(examples)}\")\n",
    "print(f\"Example length: {len(examples[0]) if examples else 'No examples'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fac1ba3f-f72b-4460-8bfa-981671ca67c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the project gutenberg ebook frankenstein or the modern prometheus by mary wollstonecraft godwin shelley contents letter letter letter letter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter chapter letter to mrs saville england st petersburgh dec th you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings i arrived here yesterday and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking i am already far north of london and as i walk in the streets of petersburgh i feel a cold northern breeze play upon my cheeks which braces my nerves and fills me with delight do you understand this feeling this breeze which has travelled from the regions towards which i am advancing gives me a foretaste of those icy \n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1341d512-fcc6-4e31-9242-f46cc1fbd618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preface supposing that truth is a woman what then is there n', 'ot ground for suspecting that all philosophers in so far as ', 'they have been dogmatists have failed to understand women th', 'at the terrible seriousness and clumsy importunity with whic', 'h they have usually paid their addresses to truth have been ', 'unskilled and unseemly methods for winning a woman certainly', ' she has never allowed herself to be won and at present ever', 'y kind of dogma stands with sad and discouraged mien if inde', 'ed it stands at all for there are scoffers who maintain that', ' it has fallen that all dogma lies on the ground nay more th', 'at it is at its last gasp but to speak seriously there are g', 'ood grounds for hoping that all dogmatizing in philosophy wh', 'atever solemn whatever conclusive and decided airs it has as', 'sumed may have been only a noble puerilism and tyronism and ', 'probably the time is at hand when it will be once and again ', 'understood what has actually sufficed for the basis of such ', 'imposing and absolute philosophical edifices as the dogmatis', 'ts have hitherto reared perhaps some popular superstition of', ' immemorial time such as the soul superstition which in the ', 'form of subject and ego superstition has not yet ceased doin']\n"
     ]
    }
   ],
   "source": [
    "print(examples[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541914ef-42d0-4cf2-9738-398bd9b2631d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a948b691-42aa-4619-81e7-078627ca7751",
   "metadata": {},
   "source": [
    "Let's create an encryption function with a random shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1b49a-4a94-467f-82cc-c0eabfd624f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac807d84-4de5-46fb-be5f-b787edf8c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['ot ground for suspecting that all philosophers in so far as ', 'they have been dogmatists have failed to understand women th']\n",
      "Encrypted: ['xc paxdwm oxa bdbynlcrwp cqjc juu yqruxbxyqnab rw bx oja jb ', 'bpmg pidm jmmv lwouibqaba pidm niqtml bw cvlmzabivl ewumv bp']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def caesar_cipher(text, shift):\n",
    "    encrypted_text = ''\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            if char.islower():\n",
    "                new_char = chr(((ord(char) - ord('a') + shift) % 26) + ord('a'))\n",
    "            else:\n",
    "                new_char = chr(((ord(char) - ord('A') + shift) % 26) + ord('A'))\n",
    "        else:\n",
    "            new_char = char\n",
    "        \n",
    "        encrypted_text += new_char\n",
    "\n",
    "    return encrypted_text\n",
    "\n",
    "encrypted_examples = [caesar_cipher(example, random.randint(1, 10)) for example in examples]\n",
    "print(f\"Original: {examples[1:3]}\")\n",
    "print(f\"Encrypted: {encrypted_examples[1:3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b935f3f-200a-49e3-b4c9-963d9652d7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ded0ac27-454d-4536-acee-187490da1770",
   "metadata": {},
   "source": [
    "Let's combine the original and encrypted examples into one file, organized as a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ac4c41f2-6f48-45ac-ae1b-914e468c7276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rtghceg uwrrqukpi vjcv vtwvj ku c yqocp yjcv vjgp ku vjgtg p', 'preface supposing that truth is a woman what then is there n'), ('xc paxdwm oxa bdbynlcrwp cqjc juu yqruxbxyqnab rw bx oja jb ', 'ot ground for suspecting that all philosophers in so far as '), ('bpmg pidm jmmv lwouibqaba pidm niqtml bw cvlmzabivl ewumv bp', 'they have been dogmatists have failed to understand women th'), ('kd dro dobbslvo cobsyecxocc kxn mvewci swzybdexsdi gsdr grsm', 'at the terrible seriousness and clumsy importunity with whic'), ('q cqnh qjen dbdjuuh yjrm cqnra jmmanbbnb cx cadcq qjen knnw ', 'h they have usually paid their addresses to truth have been '), ('votljmmfe boe votffnmz nfuipet gps xjoojoh b xpnbo dfsubjomz', 'unskilled and unseemly methods for winning a woman certainly'), (' tif ibt ofwfs bmmpxfe ifstfmg up cf xpo boe bu qsftfou fwfs', ' she has never allowed herself to be won and at present ever'), ('e qotj ul jumsg yzgtjy cozn ygj gtj joyiuaxgmkj sokt ol otjk', 'y kind of dogma stands with sad and discouraged mien if inde'), ('nm rc bcjwmb jc juu oxa cqnan jan blxoonab fqx vjrwcjrw cqjc', 'ed it stands at all for there are scoffers who maintain that'), (' pa ohz mhsslu aoha hss kvnth splz vu aol nyvbuk uhf tvyl ao', ' it has fallen that all dogma lies on the ground nay more th'), ('gz oz oy gz ozy rgyz mgyv haz zu yvkgq ykxouayre znkxk gxk m', 'at it is at its last gasp but to speak seriously there are g'), ('uuj mxuatjy lux nuvotm zngz grr jumsgzofotm ot vnoruyuvne cn', 'ood grounds for hoping that all dogmatizing in philosophy wh'), ('bufwfs tpmfno xibufwfs dpodmvtjwf boe efdjefe bjst ju ibt bt', 'atever solemn whatever conclusive and decided airs it has as'), ('uwogf oca jcxg dggp qpna c pqdng rwgtknkuo cpf vatqpkuo cpf ', 'sumed may have been only a noble puerilism and tyronism and '), ('yaxkjkuh cqn crvn rb jc qjwm fqnw rc fruu kn xwln jwm jpjrw ', 'probably the time is at hand when it will be once and again '), ('atjkxyzuuj cngz ngy gizagrre yalloikj lux znk hgyoy ul yain ', 'understood what has actually sufficed for the basis of such '), ('swzycsxq kxn klcyvedo zrsvycyzrsmkv onspsmoc kc dro nyqwkdsc', 'imposing and absolute philosophical edifices as the dogmatis'), ('ba pidm pqbpmzbw zmizml xmzpixa awum xwxctiz acxmzabqbqwv wn', 'ts have hitherto reared perhaps some popular superstition of'), (' lpphpruldo wlph vxfk dv wkh vrxo vxshuvwlwlrq zklfk lq wkh ', ' immemorial time such as the soul superstition which in the '), ('mvyt vm zbiqlja huk lnv zbwlyzapapvu ohz uva fla jlhzlk kvpu', 'form of subject and ego superstition has not yet ceased doin')]\n"
     ]
    }
   ],
   "source": [
    "data = list(zip(encrypted_examples, examples))\n",
    "print(data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89064d44-316c-4c77-bc1c-4d860c0173be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bb2299d-16a4-4561-8c8c-bda588054e6d",
   "metadata": {},
   "source": [
    "Let's create an alphabet as a set of unique characters in the text, with a space indexed separately. Then, we'll define functions to convert characters to indices and vice versa. Based on these indices, we will create tensors, since tensors work with numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9587d738-7e1d-4e2b-b8a9-54c87dec01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "def text_to_tensor(text, char_to_idx):\n",
    "    return torch.tensor([char_to_idx[ch] for ch in text], dtype=torch.long)\n",
    "\n",
    "def tensor_to_text(tensor, idx_to_char):\n",
    "    return ''.join([idx_to_char[idx.item()] for idx in tensor])\n",
    "\n",
    "data_tensors = [(text_to_tensor(enc, char_to_idx), text_to_tensor(dec, char_to_idx)) for enc, dec in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98379080-8d6c-4b28-8d5a-b904de27086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(chars)\n",
    "print(char_to_idx)\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7df8e-e06d-4bbf-862f-e64c0de97d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34df4174-63cf-4fbb-8bd5-6dffa2c7aa03",
   "metadata": {},
   "source": [
    "Let's create a CaesarDataset class, which will be convenient to feed into a DataLoader (DataLoader accepts datasets only in the form of such a class instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a646e5c4-6f93-4325-8043-cc45406f06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaesarDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = CaesarDataset(data_tensors)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617056e-f648-442e-a7e0-142ed13afd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9853d07f-b3fb-4b8b-a7eb-acf75dcabb4e",
   "metadata": {},
   "source": [
    "Creating an LSTM Network Architecture\n",
    "\n",
    "nn.Embedding — a layer for converting input character indices into dense vectors of fixed size (hidden_size).\n",
    "\n",
    "nn.LSTM — the LSTM layer itself, which will process the sequence by passing it through hidden states. It takes an input tensor of shape [batch_size, seq_length, hidden_size] and returns a sequence of hidden states.\n",
    "\n",
    "nn.Linear — a linear layer that converts the LSTM hidden state into output data of size output_size.\n",
    "\n",
    "Forward Pass:\n",
    "\n",
    "h0 and c0 — initial hidden states and cell states of the LSTM. For each batch, zero vectors are created corresponding to the number of LSTM layers.\n",
    "\n",
    "embedding(x) — the input sequence of characters (as indices) is converted into dense vectors of size hidden_size.\n",
    "\n",
    "lstm(out, (h0, c0)) — the LSTM processes the input sequence, updating the hidden states at each step and returning the final state.\n",
    "\n",
    "fc(out) — the linear layer converts the output hidden states of the LSTM into the result of the desired output_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14477ad5-dcf2-4e84-b145-3b8ac40e869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaesarEndecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(CaesarEndecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=0.2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out = self.embedding(x)\n",
    "        out, _ = self.lstm(out, (h0, c0))\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a9320-f81d-4943-97d3-837e0d782c79",
   "metadata": {},
   "source": [
    "Let's also create a decryption function that will use our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85b0dcaf-1e50-49c8-8c75-33b2c1bfdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(model, tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tensor = tensor.unsqueeze(0).to(device)\n",
    "        output = model(tensor)\n",
    "        _, decoded = torch.max(output, 2)\n",
    "    return decoded.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1dec492f-1a84-455e-aa6f-d65e27ec42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553929b-079c-40cc-80b4-93daf11ec94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852e705c-548e-4039-b59c-9e59f3e92b1c",
   "metadata": {},
   "source": [
    "Starting the Training.\n",
    "\n",
    "We will define the evaluation criterion and optimizer. We will iterate over the data in the DataLoader (where enc is the encrypted part that we feed into the model for processing, and orig is the original, unchanged text, i.e., the expected output from the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0549d2d4-01fc-443f-82c1-24a196f787dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 5.1345\n",
      "Epoch [2/50], Loss: 3.6742\n",
      "Epoch [3/50], Loss: 3.1004\n",
      "Epoch [4/50], Loss: 2.8142\n",
      "Epoch [5/50], Loss: 2.6021\n",
      "Epoch [6/50], Loss: 2.4356\n",
      "Epoch [7/50], Loss: 2.3192\n",
      "Epoch [8/50], Loss: 2.2435\n",
      "Epoch [9/50], Loss: 2.1957\n",
      "Epoch [10/50], Loss: 2.1609\n",
      "Epoch [11/50], Loss: 2.1357\n",
      "Epoch [12/50], Loss: 2.1176\n",
      "Epoch [13/50], Loss: 2.1035\n",
      "Epoch [14/50], Loss: 2.0927\n",
      "Epoch [15/50], Loss: 2.0829\n",
      "Epoch [16/50], Loss: 2.0806\n",
      "Epoch [17/50], Loss: 2.0689\n",
      "Epoch [18/50], Loss: 2.0630\n",
      "Epoch [19/50], Loss: 2.0581\n",
      "Epoch [20/50], Loss: 2.0534\n",
      "Epoch [21/50], Loss: 2.0489\n",
      "Epoch [22/50], Loss: 2.0456\n",
      "Epoch [23/50], Loss: 2.0417\n",
      "Epoch [24/50], Loss: 2.0389\n",
      "Epoch [25/50], Loss: 2.0353\n",
      "Epoch [26/50], Loss: 2.0330\n",
      "Epoch [27/50], Loss: 2.0305\n",
      "Epoch [28/50], Loss: 2.0275\n",
      "Epoch [29/50], Loss: 2.0244\n",
      "Epoch [30/50], Loss: 2.0281\n",
      "Epoch [31/50], Loss: 2.0206\n",
      "Epoch [32/50], Loss: 2.0171\n",
      "Epoch [33/50], Loss: 2.0141\n",
      "Epoch [34/50], Loss: 2.0122\n",
      "Epoch [35/50], Loss: 2.0087\n",
      "Epoch [36/50], Loss: 2.0056\n",
      "Epoch [37/50], Loss: 1.9997\n",
      "Epoch [38/50], Loss: 1.9967\n",
      "Epoch [39/50], Loss: 1.9892\n",
      "Epoch [40/50], Loss: 1.9808\n",
      "Epoch [41/50], Loss: 1.9716\n",
      "Epoch [42/50], Loss: 1.9609\n",
      "Epoch [43/50], Loss: 1.9569\n",
      "Epoch [44/50], Loss: 1.9342\n",
      "Epoch [45/50], Loss: 1.9271\n",
      "Epoch [46/50], Loss: 1.9133\n",
      "Epoch [47/50], Loss: 1.8853\n",
      "Epoch [48/50], Loss: 1.8686\n",
      "Epoch [49/50], Loss: 1.8578\n",
      "Epoch [50/50], Loss: 1.8485\n",
      "Training is completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CaesarEndecoder(input_size=len(chars), hidden_size=512, output_size=len(chars)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for enc, dec in dataloader:\n",
    "        enc, dec = enc.to(device), dec.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_dec = model(enc)\n",
    "        loss_dec = criterion(output_dec.view(-1, len(chars)), dec.view(-1))\n",
    "\n",
    "        output_enc = model(dec)\n",
    "        loss_enc = criterion(output_enc.view(-1, len(chars)), enc.view(-1))\n",
    "\n",
    "        loss = loss_dec + loss_enc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training is completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb900a-4202-4c9e-8a0f-66bbd1764c5e",
   "metadata": {},
   "source": [
    "Increasing the number of epochs to 50 resulted in a 1% improvement in accuracy, which could be significant, as we are working with textual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f230c-0ee0-47a0-ba69-f8f25bf67c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fda90ae-8d32-48c4-8837-60192d93187a",
   "metadata": {},
   "source": [
    "We can see that the loss is decreasing. However, we have to evaluate the model by testing it on a specific phrase to assess its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68932e39-baf5-4d6d-beea-2fe4f51d4875",
   "metadata": {},
   "source": [
    "Let's preprocess the test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18797d4b-af1d-476f-90fc-00a81abe17a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he who seeks to go downward will be quickly swallowed by the abyss of this place only you zarathustra love to grow on the slope of the towering pine above it her roots reach down where the rock itself looks in horror into the abyss she clings to it where all falls downward where impatience reigns of the falling stones and the waterfall she the patient one stands firm silent and alone\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"He who seeks to go downward\n",
    "will be quickly swallowed by the abyss of this place!\n",
    "Only you, Zarathustra,\n",
    "love to grow on the slope\n",
    "of the towering pine above it!\n",
    "Her roots reach down\n",
    "where the rock itself\n",
    "looks in horror into the abyss;\n",
    "she clings to it\n",
    "where all falls downward;\n",
    "where impatience reigns,\n",
    "of the falling stones and the waterfall,\n",
    "she, the patient one,\n",
    "stands firm, silent, and alone\"\"\"\n",
    "\n",
    "test_text = preprocess_text(test_text)\n",
    "test_text_enc = caesar_cipher(test_text, random.randint(1, 5))\n",
    "print(test_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561aa01-b8d5-45a8-a27e-24ddad25c2e3",
   "metadata": {},
   "source": [
    "Decode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74765315-a09b-4e8c-a9e3-60ce52de383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: he who seeks to go downward will be quickly swallowed by the abyss of this place only you zarathustra love to grow on the slope of the towering pine above it her roots reach down where the rock itself looks in horror into the abyss she clings to it where all falls downward where impatience reigns of the falling stones and the waterfall she the patient one stands firm silent and alone\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Decoded text: ee who seeks to go downward will be quickly swallowed by the abyss of this place only you yarathustra love to grow on the slope of the towering pine above it her roots reach down where the rock itself looks in horror into the abyss she clings to it where all falls downward where impatience reigns of the falling stones and the waterfall she the patient one stands firm silent and alone\n"
     ]
    }
   ],
   "source": [
    "test_tensor = text_to_tensor(test_text_enc, char_to_idx).to(device)\n",
    "\n",
    "decoded_tensor = decode_text(model, test_tensor, device)\n",
    "decoded_text = tensor_to_text(decoded_tensor, idx_to_char)\n",
    "\n",
    "print(\"Original text:\", test_text)\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\") \n",
    "print(\"Decoded text:\", decoded_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cf282-4167-4142-a37a-279b8c8008d1",
   "metadata": {},
   "source": [
    "It works correct, though not ideally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06664554-39b6-4b57-b1d0-2d900cacbb9c",
   "metadata": {},
   "source": [
    "Let's take one more example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f44a3e10-ee53-408f-9e26-2313902f2d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here where an island rises between two seas amidst a chaos of rocks like a rugged altar it is here under the blackened skies that zarathustra kindles his towering fires fiery signals for shipwrecked sailors question marks for those who know the answer this flame with its ashen gray womb its tongues reach into the cold distance its neck stretches ever higher a serpent impatiently uncoiling skyward with these markers i stake my place for my soul is this very flame insatiably yearning outward and upward upward and upward in its silent heat why did zarathustra flee from man and beast what did he escape abandoning solid ground one by one he has known six solitudes the sea alone was not lonely enough the island cast him ashore he climbed its peak and became flame he has stopped at the seventh solitude catching his own forehead on a fisherman s hook shipwrecked sailors ruined constellations seas of the future skies uninhabited by knowledge now i shall cast my line for all that is lonely answer me i call upon you impatient flame answer me catch me the fisherman upon the mountain s peak for my seventh solitude shall be my last\n"
     ]
    }
   ],
   "source": [
    "test_text2 = '''Here, where an island rises between two seas,\n",
    "Amidst a chaos of rocks, like a rugged altar,\n",
    "It is here, under the blackened skies,\n",
    "That Zarathustra kindles his towering fires—\n",
    "Fiery signals for shipwrecked sailors,\n",
    "Question marks for those who know the answer…\n",
    "\n",
    "This flame, with its ashen-gray womb,\n",
    "Its tongues reach into the cold distance,\n",
    "Its neck stretches ever higher—\n",
    "A serpent, impatiently uncoiling skyward.\n",
    "With these markers, I stake my place.\n",
    "\n",
    "For my soul is this very flame,\n",
    "Insatiably yearning outward and upward,\n",
    "Upward and upward in its silent heat.\n",
    "\n",
    "Why did Zarathustra flee from man and beast?\n",
    "What did he escape, abandoning solid ground?\n",
    "One by one, he has known six solitudes—\n",
    "The sea alone was not lonely enough.\n",
    "The island cast him ashore—he climbed its peak and became flame.\n",
    "He has stopped at the seventh solitude—\n",
    "Catching his own forehead on a fisherman’s hook.\n",
    "\n",
    "Shipwrecked sailors!\n",
    "Ruined constellations!\n",
    "Seas of the future! Skies uninhabited by knowledge!\n",
    "Now I shall cast my line for all that is lonely.\n",
    "\n",
    "Answer me, I call upon you, impatient flame—\n",
    "Answer me, catch me, the fisherman upon the mountain’s peak—\n",
    "For my seventh solitude shall be my last!'''\n",
    "\n",
    "test_text2 = preprocess_text(test_text2)\n",
    "test_text_enc2 = caesar_cipher(test_text2, random.randint(1, 5))\n",
    "print(test_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a31a1f58-3032-41fc-9304-3fecada965eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: here where an island rises between two seas amidst a chaos of rocks like a rugged altar it is here under the blackened skies that zarathustra kindles his towering fires fiery signals for shipwrecked sailors question marks for those who know the answer this flame with its ashen gray womb its tongues reach into the cold distance its neck stretches ever higher a serpent impatiently uncoiling skyward with these markers i stake my place for my soul is this very flame insatiably yearning outward and upward upward and upward in its silent heat why did zarathustra flee from man and beast what did he escape abandoning solid ground one by one he has known six solitudes the sea alone was not lonely enough the island cast him ashore he climbed its peak and became flame he has stopped at the seventh solitude catching his own forehead on a fisherman s hook shipwrecked sailors ruined constellations seas of the future skies uninhabited by knowledge now i shall cast my line for all that is lonely answer me i call upon you impatient flame answer me catch me the fisherman upon the mountain s peak for my seventh solitude shall be my last\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Decoded text: eere where an island rises between two seas amidst a chaos of rocks like a rugged altar it is here under the blackened skies that zarathustra kindles his towering fires fiery signals for shipwrecked sailors question marks for those who know the answer this flame with its ashen gray womb its tongues reach into the cold distance its neck stretches ever higher a serpent impatiently uncoiling skyward with these markers i stake my place for my soul is this very flame insatiably yearning outward and upward upward and upward in its silent heat why did aarathustra flee from man and beast what did he escape abandoning solid ground one by one he has known six solitudes the sea alone was not lonely enough the island cast him ashore he climbed its peak and became flame he has stopped at the seventh solitude catching his own forehead on a fisherman s hook shipwrecked sailors ruined constellations seas of the future skies uninhabited by knowledge now i shall cast my line for all that is lonely answer me i call upon you impatient flame answer me catch me the fisherman upon the mountain s peak for my seventh solitude shall be my last\n"
     ]
    }
   ],
   "source": [
    "test_tensor2 = text_to_tensor(test_text_enc2, char_to_idx).to(device)\n",
    "\n",
    "decoded_tensor2 = decode_text(model, test_tensor2, device)\n",
    "decoded_text2 = tensor_to_text(decoded_tensor2, idx_to_char)\n",
    "\n",
    "print(\"Original text:\", test_text2)\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\") \n",
    "print(\"Decoded text:\", decoded_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31821a59-e719-4599-afd6-98f7e18869a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e517561-66fc-47af-a4a8-0e0f25a800dd",
   "metadata": {},
   "source": [
    "Thus, the model performs well, and it makes sense to calculate the accuracy on a larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c093d4f-c1d4-480b-8884-928b4ad0d9e4",
   "metadata": {},
   "source": [
    "Let's evaluate on a large volume and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736d515-2364-48c3-8f7a-09f308dad660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f327509-9aaa-430f-9ffa-95e3e7bce7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-09 17:44:43--  https://www.gutenberg.org/files/84/84-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 2610:28:3090:3000:0:bad:cafe:47, 152.19.134.47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|2610:28:3090:3000:0:bad:cafe:47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 428995 (419K) [text/plain]\n",
      "Saving to: ‘84-0.txt.1’\n",
      "\n",
      "84-0.txt.1          100%[===================>] 418.94K   345KB/s    in 1.2s    \n",
      "\n",
      "2025-05-09 17:44:45 (345 KB/s) - ‘84-0.txt.1’ saved [428995/428995]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.gutenberg.org/files/84/84-0.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0e8b4f5-3e32-40d6-892b-2c88e1fcfe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 419434\n",
      "Processed length: 407791\n",
      "Processed examples: 6796\n",
      "Example length: 60\n",
      "Original: start of the project gutenberg ebook frankenstein or the mod\n",
      "Encrypted: abizb wn bpm xzwrmkb ocbmvjmzo mjwws nzivsmvabmqv wz bpm uwl\n",
      "Test examples: 6796\n",
      "Example length: 60\n"
     ]
    }
   ],
   "source": [
    "with open('84-0.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print('Original length:', len(text))\n",
    "\n",
    "text = preprocess_text(text)\n",
    "print('Processed length:', len(text))\n",
    "\n",
    "example_length = 60\n",
    "text = text[:(len(text) // example_length) * example_length]\n",
    "test_examples = [text[i:i + example_length] for i in range(0, len(text), example_length)]\n",
    "\n",
    "test_examples = [example for example in test_examples if len(example) == example_length]\n",
    "\n",
    "print(f\"Processed examples: {len(test_examples)}\")\n",
    "print(f\"Example length: {len(test_examples[0]) if test_examples else 'No examples'}\")\n",
    "\n",
    "encrypted_test_examples = [caesar_cipher(example, random.randint(1, 10)) for example in test_examples]\n",
    "print(f\"Original: {test_examples[0]}\")\n",
    "print(f\"Encrypted: {encrypted_test_examples[0]}\")\n",
    "\n",
    "test_examples_tensor = [text_to_tensor(example, char_to_idx) for example in encrypted_test_examples]\n",
    "\n",
    "test_dataset = CaesarDataset(test_examples_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Test examples: {len(test_examples_tensor)}\")\n",
    "print(f\"Example length: {len(test_examples_tensor[0]) if test_examples_tensor else 'No examples'}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a817a5-195f-4341-bc74-b5a9db776a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6312664-f6f1-4e44-a8ec-648e75aa5af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59c43e7-9929-4991-bb89-0848ea6fa36b",
   "metadata": {},
   "source": [
    "Futher was an issue with shuffling – the indices were lost, and it became difficult to restore the correspondence. At the same time, the goal was to work with shuffling to ensure the examples were not related to each other. Therefore, it was decided to fix the correspondence of indices at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b041555b-69a8-44d8-98db-c3982c54f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, test_loader, device, idx_to_char, shuffled_originals, indices, show_last_n=5):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_outputs = []\n",
    "\n",
    "    restored_originals = [None] * len(indices)\n",
    "    for shuffled_idx, original_idx in enumerate(indices):\n",
    "        restored_originals[shuffled_idx] = shuffled_originals[shuffled_idx]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_size = test_loader.batch_size\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            inputs = data.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 2)\n",
    "\n",
    "            for i in range(inputs.shape[0]):\n",
    "                index = batch_idx * batch_size + i\n",
    "                if index >= len(restored_originals):\n",
    "                    continue\n",
    "\n",
    "                original_text = restored_originals[index]\n",
    "                predicted_text = ''.join([idx_to_char[idx.item()] for idx in predicted[i]])\n",
    "\n",
    "                all_outputs.append((original_text, predicted_text))\n",
    "\n",
    "                correct += sum(1 for orig, pred in zip(original_text, predicted_text) if orig == pred)\n",
    "                total += len(original_text)\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(\"\\n--- Showing last {} results ---\".format(show_last_n))\n",
    "    for original_text, predicted_text in all_outputs[-show_last_n:]:\n",
    "        print(f\"Original:   {original_text}\")\n",
    "        print(f\"Decoded:    {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "96364753-ce27-4128-a8f5-fdf911d2f165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Showing last 5 results ---\n",
      "Original:   y resolution is firm but my hopes fluctuate and my spirits a\n",
      "Decoded:    t tysieoncin is firm but my hopes fluctuate and my spirits a\n",
      "--------------------------------------------------\n",
      "Original:   oon return to england do you then really return alas yes i c\n",
      "Decoded:    oon return to england do you then really return alas yes i c\n",
      "--------------------------------------------------\n",
      "Original:   as apparently united by no link to any other being in existe\n",
      "Decoded:    ts aiitkently united by no link to any other being in existe\n",
      "--------------------------------------------------\n",
      "Original:   oy except as it is mirrored also in your dear countenances w\n",
      "Decoded:    tj ixcitt ao it is mirrored also in your dear countenances w\n",
      "--------------------------------------------------\n",
      "Original:   ke but a very sorry chemist if he attended to that departmen\n",
      "Decoded:    ic dut a very sorry chemist if he attended to that departmen\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = calculate_accuracy(model, test_loader, device, idx_to_char, shuffled_test_examples, indices, show_last_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ad7c2-01dc-4cb6-af72-caee855f7052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69676cf9-f8ce-4e06-a9ef-a4d49f5b7cd3",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Model works good. Using such a model allows decryption without specifying the shift length, which is typically required in Python functions. This is a clear advantage of the model, despite its more complex implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1590d-7738-452e-b4c8-0ecff75cc99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471808d-f25b-4f23-922b-7c0f22ee3874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
